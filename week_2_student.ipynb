{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import your data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_starter = pd.read_csv(\"ks-projects-201801.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Columns to upper case \n",
    "\n",
    "- Lets convert the columns to uppercase. \n",
    "- For this we will use the `.upper()` method\n",
    "- To do this we need to address only the columns \n",
    "- Start with `kick_starter.columns =`  \n",
    "- Did you get an error? \n",
    "- Hints below if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Did you get an error? \n",
    "\n",
    "The reason we can't simply use `.upper()` on the DataFrame's column names is that \n",
    "- .upper() is a method designed for strings \n",
    "- while DataFrame.columns is an Index object (a collection of strings). \n",
    "  \n",
    "  \n",
    "#### Let's break it down:\n",
    "\n",
    "Why Not .upper() Directly?\n",
    "Data Type Difference:\n",
    "- `df.columns` returns an Index object, not a single string. \n",
    "- The `.upper()` method only works on individual strings \n",
    "- columns are stored in a list-like structure (Index).\n",
    "\n",
    "#### Broadcasting Needed:\n",
    "To apply `.upper()` to each column name, we need to broadcast it over all the column names. <br> \n",
    "Pandas provides the `.str` accessor to handle such operations efficiently.\n",
    "\n",
    "#### Why Use `.str.upper()`?\n",
    "The `.str` accessor in pandas allows us to apply string methods like `.upper()` to each element in the Index object.\n",
    "`.str.upper()` ensures that the transformation applies to all column names in one step, treating them as individual strings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Columns to title case \n",
    "\n",
    "- Start the same way we did above\n",
    "- Rather than `.upper()` we will use `.title()`\n",
    "- What did that do to the columns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Similar Methods  \n",
    "\n",
    "1. `str.title()`\n",
    "Capitalizes the first letter of each word in the column names.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.title()\n",
    "    ```\n",
    "    \n",
    "        Example:\n",
    "        \"project_name\" becomes \"Project_Name\"\n",
    "\n",
    "2. `str.lower()`\n",
    "Converts all column names to lowercase.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.lower()\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \"Project_Name\" becomes \"project_name\"\n",
    "\n",
    "3. `str.upper()`\n",
    "Converts all column names to uppercase.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.upper()\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \"Project_Name\" becomes \"PROJECT_NAME\"\n",
    "\n",
    "4. `str.strip()`\n",
    "Removes leading and trailing whitespace from column names.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.strip()\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \" Project_Name \" becomes \"Project_Name\"\n",
    "\n",
    "5. `str.replace()`\n",
    "Replaces a specific substring in the column names with another string.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.replace('_', ' ')\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \"Project_Name\" becomes \"Project Name\"\n",
    "\n",
    "6. `str.contains()` (for filtering columns)\n",
    "(Not for renaming, but useful for selecting columns.)\n",
    "Checks if column names contain a specific substring.\n",
    "\n",
    "    ```js\n",
    "    columns_with_name = kick_starter.columns[kick_starter.columns.str.contains('name')]\n",
    "    print(columns_with_name)\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        Returns column names that include \"name\".\n",
    "\n",
    "7. str.startswith() / str.endswith()\n",
    "Filters columns based on their starting or ending substring.\n",
    "\n",
    "    ```js\n",
    "    // Columns that start with 'proj'\n",
    "    columns_starting_with_proj = kick_starter.columns[kick_starter.columns.str.startswith('proj')]\n",
    "\n",
    "    // Columns that end with 'name'\n",
    "    columns_ending_with_name = kick_starter.columns[kick_starter.columns.str.endswith('name')]\n",
    "    ```\n",
    "\n",
    "8. str.capitalize()\n",
    "Capitalizes the first letter of the first word in each column name.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.capitalize()\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \"project_name\" becomes \"Project_name\"\n",
    "\n",
    "9. `str.replace()` with regex\n",
    "You can also use regex=True for complex replacements.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = kick_starter.columns.str.replace(r'\\s+', '_', regex=True)\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        Replaces spaces with underscores.\n",
    "\n",
    "10. Combining Methods\n",
    "You can chain multiple methods together.\n",
    "\n",
    "    ```js\n",
    "    kick_starter.columns = (\n",
    "        kick_starter.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_')\n",
    "    )\n",
    "    ```\n",
    "\n",
    "        Example:\n",
    "        \" Project Name \" becomes \"project_name\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove White Space and Underscores \n",
    "\n",
    "Here we will chain some methods together to accomplish the task.  \n",
    "Our goal is to remove any white space that might be before or after our column names.   \n",
    "Then we will remove underscore and replace them with a space. \n",
    "\n",
    "- Start with `kick_starter.columns =` \n",
    "- Then strip the white space \n",
    "- Then handle replacing the underscore \n",
    "- This should all be ones line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping columns We Don't Need \n",
    "\n",
    "### Why Do We Drop Columns in Data Analytics?\n",
    "- **Reduce Noise:** Irrelevant columns can obscure important patterns.\n",
    "\n",
    "- **Improve Efficiency:** Fewer columns mean faster computations.\n",
    "\n",
    "- **Prevent Overfitting:** Reducing irrelevant features helps models generalize better.\n",
    "\n",
    "- **Enhance Clarity:** Simplifies data interpretation and reporting.\n",
    "\n",
    "- **Ensure Privacy:** Removes sensitive or personally identifiable information (PII).\n",
    "\n",
    "- **Avoid Redundancy:** Drops duplicate or highly correlated features.\n",
    "\n",
    "- **Focus on Goals:** Keeps only columns relevant to the analysis objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above in mind let's pick some columns to drop. First we will need to identify some questions and be sure we don't drop columns we don't need. Also we can just infer we may not need certain columns. An example being \"Id\". We have no other data to reference this column with so we can remove it. \n",
    "\n",
    "Things we want to accomplish with our data:\n",
    "- Filter to US only in Country \n",
    "- Goal status for plot \n",
    "- What category has the most backers. \n",
    "- What has the highest backing amount\n",
    "\n",
    "With the above questions we can determine columns to remove. \n",
    "- 'Id' : We can remove this because we can't reference this to anything with our limited data \n",
    "- 'Name' : We will want to keep this so we know what project is what \n",
    "- 'Category' : We will primarily look at Main Category but this could be helpful\n",
    "- 'Main Category' : We have a goal directly related to this column\n",
    "- 'Currency' : We have a goal related to Currency so we will keep this \n",
    "- 'Deadline' : We wont need this column as we have no goals related to this column \n",
    "- 'Goal' : we will keep this as and Usd Goal Real\n",
    "- 'Launched' : We wont need this column as we have no goals related to this column \n",
    "- 'Pledged' : We will keep this and Usd Pledged Real\n",
    "- 'State' :  keep ...\n",
    "- 'Backers' : keep ...\n",
    "- 'Country' : keep ...\n",
    "- 'Usd Pledged' : keep  ...\n",
    "- 'Usd Pledged Real' : keep ...\n",
    "- 'Usd Goal Real' : keep ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the list above lest use the `.drop()` method to remove the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address Nulls Remove vs 0 vs Back Fill ect. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Remove Rows with Null Values\n",
    "Use Case: When missing data is sparse or not crucial to the analysis.\n",
    "\n",
    "```python\n",
    "# Drop rows with any NaN values\n",
    "kick_starter_cleaned = kick_starter.dropna()\n",
    "\n",
    "# Drop rows where specific columns have NaN\n",
    "kick_starter_cleaned = kick_starter.dropna(subset=['Column1', 'Column2'])\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- dropna() removes rows where any column has NaN.\n",
    "- subset targets specific columns only.\n",
    "\n",
    "### 2. Fill Nulls with Zero\n",
    "Use Case: When missing values represent quantities like counts or amounts.\n",
    "\n",
    "```python\n",
    "# Fill all NaN values with 0\n",
    "kick_starter_filled = kick_starter.fillna(0)\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- Filling with 0 ensures calculations like sums are not affected by missing data.\n",
    "\n",
    "### 3. Fill Nulls with a Specific Value\n",
    "Use Case: When missing data should default to a constant like \"Unknown.\"\n",
    "\n",
    "```python\n",
    "# Fill NaN in a specific column with 'Unknown'\n",
    "kick_starter['Category'] = kick_starter['Category'].fillna('Unknown')\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- This is useful for categorical columns where missing data can be treated as a new category.\n",
    "\n",
    "### 4. Forward Fill (Use Previous Value)\n",
    "Use Case: For time-series data or when prior values can logically fill gaps.\n",
    "\n",
    "```python\n",
    "# Fill NaN using the previous value in the same column\n",
    "kick_starter_ffill = kick_starter.fillna(method='ffill')\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- Uses the last valid value to fill the NaN, ideal for propagating information in sequences.\n",
    "\n",
    "\n",
    "### 5. Backward Fill (Use Next Value)\n",
    "Use Case: Similar to forward fill, but uses subsequent values instead.\n",
    "\n",
    "```python\n",
    "# Fill NaN using the next value in the same column\n",
    "kick_starter_bfill = kick_starter.fillna(method='bfill')\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- Backfills using the next available value, ideal when later data can logically fill gaps.\n",
    "\n",
    "### 6. Fill with Column Mean/Median/Mode\n",
    "Use Case: For numerical data where imputing missing values based on the distribution is valid.\n",
    "\n",
    "```python\n",
    "# Fill NaN with the column mean\n",
    "kick_starter['Amount'] = kick_starter['Amount'].fillna(kick_starter['Amount'].mean())\n",
    "\n",
    "# Fill NaN with the column median\n",
    "kick_starter['Amount'] = kick_starter['Amount'].fillna(kick_starter['Amount'].median())\n",
    "\n",
    "# Fill NaN with the column mode (most frequent value)\n",
    "kick_starter['Category'] = kick_starter['Category'].fillna(kick_starter['Category'].mode()[0])\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- mean and median are for numerical data.\n",
    "- mode is best for categorical data.\n",
    "\n",
    "### 7. Interpolate Missing Values\n",
    "Use Case: For continuous data where missing values can be estimated.\n",
    "\n",
    "```python\n",
    "# Linear interpolation\n",
    "kick_starter_interpolated = kick_starter.interpolate(method='linear')\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- Interpolates missing values based on surrounding data points. Useful for numerical and time-series data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are just going to drop all missing values to keep it \n",
    "- use the `.dropna()` method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the DataFrame to Include Only US-based Records\n",
    "\n",
    "- **Step 1:** \n",
    "  - Identify the column that contains country information.\n",
    "\n",
    "- **Step 2:** \n",
    "  - Understand the structure of the DataFrame.\n",
    "  - You will need to filter the rows where the value in the \"Country\" column is equal to \"US\" (the United States).\n",
    "\n",
    "- **Step 3:** \n",
    "  - Use a filtering condition.\n",
    "  - You'll want to create a condition that checks if the \"Country\" column contains the value \"US\". This will result in a boolean series (True or False for each row).\n",
    "\n",
    "- **Step 4:** \n",
    "  - Apply the condition to the DataFrame.\n",
    "  - Once you have the condition, apply it to the DataFrame to return only the rows where the condition is true.\n",
    "\n",
    "- **Step 5:** \n",
    "  - Assign the result back to the DataFrame.\n",
    "  - After filtering, ensure you store the filtered DataFrame back into the original variable to update it.\n",
    "\n",
    "- **Tips:**\n",
    "  - Remember, the condition should be based on the value of the \"Country\" column.\n",
    "  - Be careful with case sensitivity (e.g., \"US\" vs \"us\").\n",
    "  - This will be one line of code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Total, Mean, and Median of Backers\n",
    "\n",
    "**Step 1:** Identify the column that contains the number of backers.\n",
    "\n",
    "**Step 2:** Calculate the total number of backers.\n",
    "\n",
    "**Step 3:** Calculate the mean (average) number of backers and round 2 places.\n",
    "\n",
    "**Step 4:** Calculate the median number of backers.\n",
    "\n",
    "**Step 5:** Display the results using print().\n",
    "\n",
    "**Step 6:** Ensure formatting of your print statement more readable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the Category with the Most Backers\n",
    "\n",
    "**Step 1:** Identify the columns for \"Backers\" and \"Category\".\n",
    "\n",
    "**Step 2:** Group the data by the \"Category\" column.\n",
    "- Use the `groupby()` function to group the data by the \"Category\" column, which will allow you to perform operations on each category.\n",
    "\n",
    "**Step 3:** Sum the backers for each category.\n",
    "- After grouping, apply the `sum()` function to get the total number of backers for each category.\n",
    "\n",
    "**Step 4:** Find the category with the maximum total number of backers.\n",
    "- Use the `idxmax()` function to find the category that has the highest sum of backers.\n",
    "\n",
    "**Step 5:** Display the result.\n",
    "Print out the category with the most backers and the number of backers it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the Categories by Number of Backers in Descending Order\n",
    "\n",
    "**Step 1:** Using the `category_backers` variable.\n",
    "This variable contains the total number of backers for each category, which was previously calculated by grouping the data and summing the backers for each category.\n",
    "\n",
    "**Step 2:** Use the `sort_values()` function to sort the `category_backers`.\n",
    "The sort_values() function is used to sort the values in a Series or DataFrame. You need to specify the ascending parameter to control the order.\n",
    "\n",
    "**Step 3:** Set `ascending=False` to sort in descending order.\n",
    "By setting ascending=False, you will sort the data so that the category with the most backers appears first.\n",
    "\n",
    "**Step 4:** Assign the sorted result back to the `category_backers` variable.\n",
    "Ensure that the sorted result is saved to the same variable so it updates with the new order.\n",
    "\n",
    "**Step 5:** Print the top 10 categories. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the last 10 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complex groupby and plots\n",
    "\n",
    "This code will only work if install matplotlib and have done your code correct as it uses your variables column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for successful projects\n",
    "filtered_data = kick_starter[kick_starter['State'] == 'successful']\n",
    "\n",
    "# Group by Category and State and sum the specified columns\n",
    "top_ten_cats = filtered_data.groupby(['Category', 'State'])[['Backers', 'Usd Pledged Real']].sum().reset_index()\n",
    "\n",
    "# Sort the entire DataFrame by 'Usd Pledged Real' in descending order\n",
    "top_ten_cats = top_ten_cats.sort_values(by='Usd Pledged Real', ascending=False)\n",
    "\n",
    "top_ten_cats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# 1. Top 10 Categories by Total Pledged Amount\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_pledged = top_ten_cats.groupby('Category')['Usd Pledged Real'].sum().nlargest(10)\n",
    "\n",
    "# Highlight the highest value in blue, others in light grey\n",
    "colors = ['blue' if i == 0 else 'lightgrey' for i in range(len(top_pledged))]\n",
    "\n",
    "plt.bar(top_pledged.index, top_pledged.values, color=colors)\n",
    "\n",
    "# Add value only on the blue bar (the highest one)\n",
    "plt.text(0, top_pledged.values[0], f'{top_pledged.values[0]:,.0f}', \n",
    "         ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Formatting for x-axis labels and title\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Top 10 Categories by Total Pledged Amount')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Total Pledged Amount (USD)')\n",
    "\n",
    "# Add comma formatting for y-axis\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Top 10 Categories by Number of Backers\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_backers = top_ten_cats.groupby('Category')['Backers'].sum().nlargest(10)\n",
    "\n",
    "# Highlight the highest value in blue, others in light grey\n",
    "colors = ['blue' if i == 0 else 'lightgrey' for i in range(len(top_backers))]\n",
    "\n",
    "plt.bar(top_backers.index, top_backers.values, color=colors)\n",
    "\n",
    "# Add value only on the blue bar (the highest one)\n",
    "plt.text(0, top_backers.values[0], f'{top_backers.values[0]:,.0f}', \n",
    "         ha='center', va='bottom', fontsize=12, color='black')\n",
    "\n",
    "# Formatting for x-axis labels and title\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Top 10 Categories by Number of Backers')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Number of Backers')\n",
    "\n",
    "# Add comma formatting for y-axis\n",
    "plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
